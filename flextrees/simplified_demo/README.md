# ICDTA4FL 简化版演示

## 概述

这是一个 ICDTA4FL (Interpretable Client Decision Tree Aggregation for Federated Learning) 的简化版演示。该方法旨在实现联邦学习环境下的可解释性决策树聚合。

本演示简化了原始代码，使其更易于理解，同时保留了核心算法流程。

## 核心概念

ICDTA4FL 算法主要包含以下几个核心概念：

1. **规则提取**：从客户端的决策树模型中提取规则（决策路径）
2. **规则筛选**：选择表现良好的客户端模型和规则
3. **规则聚合**：将多个客户端的规则合并成一个全局决策树
4. **可解释性**：最终的全局模型保持决策树的可解释性特点

## 详细流程解释

### 1. 规则提取流程

规则提取是从决策树中提取决策路径（从根节点到叶节点的路径）的过程，每条路径就是一条规则。

#### 技术细节：

1. **决策路径**：每条从根节点到叶节点的路径代表一条规则
2. **分支识别**：通过遍历树的结构来找到所有叶节点，然后向上追溯到根节点
3. **规则生成**：每个内部节点表示一个条件（特征和阈值的比较），将这些条件组合起来就形成了一条规则
4. **概率计算**：每条规则都与叶节点的类别概率分布相关联

在代码中，规则提取主要通过 `ConjunctionSet` 类实现，它会：
- 找到决策树的所有叶节点
- 对每个叶节点，向上追溯获取完整的决策路径
- 将每条路径转换为规则，包含特征条件和类别概率分布
- 将所有规则存储在 `branches_lists` 数据结构中

### 2. 规则筛选流程

规则筛选旨在选择高质量的客户端模型，去除可能有噪声或不准确的客户端。

#### 技术细节：

1. **交叉评估**：每个客户端的模型在所有其他客户端的数据上进行评估
2. **性能计算**：计算每个模型在每个客户端数据上的准确率和F1分数
3. **阈值筛选**：根据性能指标（如平均性能或百分位数）设定阈值，选择超过阈值的模型
4. **适应性选择**：如果没有模型超过阈值，选择性能最好的一个模型

在简化演示中，筛选过程通过以下步骤实现：
- 评估每个客户端的决策树在所有客户端数据上的性能
- 计算平均性能或应用其他筛选策略
- 选择符合条件的模型索引，用于后续聚合

### 3. 规则聚合流程

规则聚合是将多个客户端的规则合并成一个统一的全局模型的过程。

#### 技术细节：

1. **规则合并**：收集所有选中客户端的规则集合
2. **去重**：移除重复或冗余的规则
3. **概率调整**：调整每条规则的概率权重
4. **新决策树构建**：基于合并后的规则集构建一个新的决策树模型

聚合过程中的关键步骤：
- 通过 `generate_cs_dt_branches_from_list` 函数将多个规则集合并
- 使用 `ConjunctionSet.aggregate_branches` 方法聚合不同客户端的规则
- 通过 `ConjunctionSet.buildConjunctionSet` 构建统一的规则集
- 删除重复规则并规范化概率
- 使用 `TreeBranch` 类从规则集构建全局决策树

### 4. 全局模型评估

最后，评估全局聚合模型在测试数据上的性能，验证聚合效果。

## 技术重点

1. **规则表示**：规则通过特征索引、比较操作符和阈值的组合表示，例如 "特征3 <= 0.5 AND 特征1 > 2.3"
2. **概率分布**：每条规则关联一个类别概率分布，表示该规则预测每个类别的概率
3. **分支树**：`TreeBranch` 类是从规则集重新构建决策树的核心，它实现了基于规则的分割逻辑
4. **熵最小化**：在构建全局树时，使用信息增益（熵减少）来选择最佳分割点

## 与原始代码的区别

为了简化理解，本演示与原始代码相比做了以下改动：

1. 移除了分布式计算框架相关代码，使用直接函数调用
2. 简化了数据处理和模型配置
3. 仅实现了CART决策树（原代码支持ID3和C4.5）
4. 保留了核心的规则提取、筛选和聚合逻辑

## 运行指南

要运行此简化演示，确保已安装所需的依赖：

```bash
pip install scikit-learn pandas numpy
```

然后直接运行脚本：

```bash
python simplified_demo.py
``` 