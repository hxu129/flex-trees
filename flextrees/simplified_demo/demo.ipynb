{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# 为了简化，这里我们直接使用原始代码中的ConjunctionSet类\n",
    "from flextrees.utils.ConjunctionSet import ConjunctionSet\n",
    "# 使用utils_function_aggregator来聚合规则\n",
    "from flextrees.utils.utils_function_aggregator import generate_cs_dt_branches_from_list\n",
    "from flextrees.utils.branch_tree import TreeBranch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置参数\n",
    "N_CLIENTS = 5  # 客户端数量\n",
    "DATA_DISTRIBUTION = 'iid'  # 'iid' 或 'non-iid'\n",
    "MODEL_TYPE = 'cart'  # 模型类型，简化版只实现'cart'\n",
    "MAX_DEPTH = 5  # 决策树最大深度\n",
    "    \n",
    "# 筛选参数\n",
    "FILTERING_METHOD = 'mean'  # 筛选方法\n",
    "ACC_THRESHOLD = 0.6  # 准确率阈值\n",
    "F1_THRESHOLD = 0.5  # F1分数阈值\n",
    "\n",
    "# 3. 配置本地模型参数\n",
    "local_model_params = {\n",
    "    'max_depth': MAX_DEPTH,\n",
    "    'criterion': 'gini',\n",
    "    'splitter': 'best',\n",
    "    'model_type': MODEL_TYPE,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "加载数据集...\n",
      "数据集加载完成，特征数量: 109\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(dataset_name='adult', categorical=False):\n",
    "    \"\"\"加载指定的数据集\"\"\"\n",
    "    try:\n",
    "        # 这里简化为手动加载adult数据集\n",
    "        from flextrees.datasets import adult\n",
    "        return adult(ret_feature_names=True, categorical=categorical)\n",
    "    except ImportError:\n",
    "        # 如果找不到特定的数据集，使用模拟数据\n",
    "        print(\"未找到指定数据集，使用模拟数据\")\n",
    "        from sklearn.datasets import make_classification\n",
    "        X, y = make_classification(n_samples=1000, n_features=10, n_classes=2, random_state=42)\n",
    "        feature_names = [f'x{i}' for i in range(X.shape[1])]\n",
    "        X_df = pd.DataFrame(X, columns=feature_names)\n",
    "        y_df = pd.Series(y)\n",
    "        \n",
    "        # 创建数据集对象\n",
    "        class Dataset:\n",
    "            def __init__(self, X, y):\n",
    "                self.X_data = X\n",
    "                self.y_data = y\n",
    "            def to_numpy(self):\n",
    "                return self.X_data.to_numpy(), self.y_data.to_numpy()\n",
    "                \n",
    "        train_data = Dataset(X_df[:800], y_df[:800])\n",
    "        test_data = Dataset(X_df[800:], y_df[800:])\n",
    "        return train_data, test_data, feature_names\n",
    "\n",
    "# 1. 加载数据\n",
    "print(f\"\\n加载数据集...\")\n",
    "train_data, test_data, feature_names = load_dataset(categorical=False)\n",
    "print(f\"数据集加载完成，特征数量: {len(feature_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(X_data=len:22792\n",
       "is_generator:False\n",
       "iterable:[[4.800e+01 0.000e+00 0.000e+00 ... 1.000e+00 0.000e+00 1.000e+00]\n",
       " [2.500e+01 0.000e+00 0.000e+00 ... 0.000e+00 0.000e+00 1.000e+00]\n",
       " [4.100e+01 7.430e+03 0.000e+00 ... 1.000e+00 1.000e+00 0.000e+00]\n",
       " ...\n",
       " [4.200e+01 0.000e+00 0.000e+00 ... 1.000e+00 0.000e+00 1.000e+00]\n",
       " [3.300e+01 0.000e+00 0.000e+00 ... 1.000e+00 1.000e+00 0.000e+00]\n",
       " [3.100e+01 5.178e+03 0.000e+00 ... 1.000e+00 0.000e+00 1.000e+00]]\n",
       "iterable_indexes:[    0     1     2 ... 22789 22790 22791]\n",
       "storage:{}, y_data=len:22792\n",
       "is_generator:False\n",
       "iterable:[0 0 1 ... 1 0 1]\n",
       "iterable_indexes:[    0     1     2 ... 22789 22790 22791]\n",
       "storage:{})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "将数据分发到 5 个客户端 (iid 分布)...\n"
     ]
    }
   ],
   "source": [
    "def split_data_to_clients(data, n_clients=5, iid=True):\n",
    "    \"\"\"将数据分割给多个客户端\"\"\"\n",
    "    X, y = data.X_data.to_numpy(), data.y_data.to_numpy()\n",
    "    client_data = []\n",
    "    \n",
    "    if iid:\n",
    "        # IID分割: 随机均匀分割\n",
    "        indices = np.random.permutation(len(X))\n",
    "        chunk_size = len(indices) // n_clients\n",
    "        \n",
    "        for i in range(n_clients):\n",
    "            start_idx = i * chunk_size\n",
    "            end_idx = (i + 1) * chunk_size if i < n_clients - 1 else len(indices)\n",
    "            client_indices = indices[start_idx:end_idx]\n",
    "            \n",
    "            # 创建数据集对象\n",
    "            class ClientDataset:\n",
    "                def __init__(self, X, y):\n",
    "                    self.X_data = pd.DataFrame(X)\n",
    "                    self.y_data = pd.Series(y)\n",
    "            \n",
    "            client_data.append(ClientDataset(X[client_indices], y[client_indices]))\n",
    "    else:\n",
    "        # Non-IID分割: 按类别偏向分配\n",
    "        classes = np.unique(y)\n",
    "        client_indices = [[] for _ in range(n_clients)]\n",
    "        \n",
    "        # 按类别分配\n",
    "        for c in classes:\n",
    "            idx = np.where(y == c)[0]\n",
    "            np.random.shuffle(idx)\n",
    "            \n",
    "            # 偏向分配\n",
    "            if len(classes) >= n_clients:\n",
    "                # 如果类别数多于客户端数，每个客户端主要分配一种类型\n",
    "                client_id = int(c % n_clients)\n",
    "                client_indices[client_id].extend(idx[:int(len(idx)*0.6)])\n",
    "                \n",
    "                # 其余的随机分配\n",
    "                remaining_idx = idx[int(len(idx)*0.6):]\n",
    "                np.random.shuffle(remaining_idx)\n",
    "                chunk_size = len(remaining_idx) // n_clients\n",
    "                for i in range(n_clients):\n",
    "                    start_idx = i * chunk_size\n",
    "                    end_idx = (i + 1) * chunk_size if i < n_clients - 1 else len(remaining_idx)\n",
    "                    client_indices[i].extend(remaining_idx[start_idx:end_idx])\n",
    "            else:\n",
    "                # 如果类别数少于客户端数，将每个类别平均分配\n",
    "                chunk_size = len(idx) // n_clients\n",
    "                for i in range(n_clients):\n",
    "                    start_idx = i * chunk_size\n",
    "                    end_idx = (i + 1) * chunk_size if i < n_clients - 1 else len(idx)\n",
    "                    client_indices[i].extend(idx[start_idx:end_idx])\n",
    "        \n",
    "        # 创建数据集\n",
    "        for indices in client_indices:\n",
    "            class ClientDataset:\n",
    "                def __init__(self, X, y):\n",
    "                    self.X_data = pd.DataFrame(X)\n",
    "                    self.y_data = pd.Series(y)\n",
    "            \n",
    "            client_data.append(ClientDataset(X[indices], y[indices]))\n",
    "    \n",
    "    return client_data\n",
    "\n",
    "    \n",
    "# 2. 将数据分发到客户端\n",
    "print(f\"\\n将数据分发到 {N_CLIENTS} 个客户端 ({DATA_DISTRIBUTION} 分布)...\")\n",
    "client_data = split_data_to_clients(train_data, N_CLIENTS, DATA_DISTRIBUTION == 'iid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 树训练和规则提取函数\n",
    "def train_local_model(client_data, model_params):\n",
    "    \"\"\"在本地训练决策树并提取规则\"\"\"\n",
    "    # 根据模型类型创建分类器\n",
    "    model_type = model_params.get('model_type', 'cart')\n",
    "    \n",
    "    # 创建分类器，这里简化只使用CART决策树\n",
    "    clf = DecisionTreeClassifier(\n",
    "        random_state=42,\n",
    "        min_samples_split=max(1.0, int(0.02 * len(client_data.X_data))),\n",
    "        max_depth=model_params.get('max_depth', 5),\n",
    "        criterion=model_params.get('criterion', 'gini'),\n",
    "        splitter=model_params.get('splitter', 'best')\n",
    "    )\n",
    "    \n",
    "    # 准备训练数据\n",
    "    X_data, y_data = client_data.X_data.to_numpy(), client_data.y_data.to_numpy()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # 训练模型\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # 模型评估\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    print(f\"客户端本地模型 - 准确率: {acc:.4f}, F1分数: {f1:.4f}, 训练样本数: {len(X_train)}, 测试样本数: {len(X_test)}\")\n",
    "    \n",
    "    # 从决策树提取规则\n",
    "    feature_names = [f'x{i}' for i in range(X_data.shape[1])]\n",
    "    feature_types = ['int'] * len(feature_names)\n",
    "    \n",
    "    # 创建规则集合\n",
    "    local_cs = ConjunctionSet(\n",
    "        feature_names=feature_names, \n",
    "        original_data=X_train, \n",
    "        pruning_x=X_train, \n",
    "        pruning_y=y_train,\n",
    "        model=[clf],  # 模型列表\n",
    "        feature_types=feature_types,  # 特征类型\n",
    "        amount_of_branches_threshold=3000,  # 分支数量阈值\n",
    "        minimal_forest_size=1,  # 最小森林大小\n",
    "        estimators=clf,  # 估计器\n",
    "        filter_approach='probability',  # 过滤方法\n",
    "        personalized=False  # 是否个性化\n",
    "    )\n",
    "    \n",
    "    # 创建返回结果\n",
    "    result = {\n",
    "        'local_tree': clf,\n",
    "        'local_cs': local_cs,\n",
    "        'local_branches': local_cs.get_branches_list(),\n",
    "        'local_branches_df': local_cs.get_conjunction_set_df().round(decimals=5),\n",
    "        'local_classes': clf.classes_,\n",
    "        'X_test': X_test,\n",
    "        'y_test': y_test,\n",
    "        'local_acc': acc,\n",
    "        'local_f1': f1\n",
    "    }\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "第1步: 训练本地模型并提取规则...\n",
      "\n",
      "客户端1训练中...\n",
      "客户端本地模型 - 准确率: 0.8542, F1分数: 0.7612, 训练样本数: 3646, 测试样本数: 912\n",
      "Estimators: DecisionTreeClassifier(max_depth=5, min_samples_split=91, random_state=42)\n",
      "AQUÍr\n",
      "\n",
      "客户端2训练中...\n",
      "客户端本地模型 - 准确率: 0.8564, F1分数: 0.7801, 训练样本数: 3646, 测试样本数: 912\n",
      "Estimators: DecisionTreeClassifier(max_depth=5, min_samples_split=91, random_state=42)\n",
      "AQUÍr\n",
      "\n",
      "客户端3训练中...\n",
      "客户端本地模型 - 准确率: 0.8410, F1分数: 0.7699, 训练样本数: 3646, 测试样本数: 912\n",
      "Estimators: DecisionTreeClassifier(max_depth=5, min_samples_split=91, random_state=42)\n",
      "AQUÍr\n",
      "\n",
      "客户端4训练中...\n",
      "客户端本地模型 - 准确率: 0.8432, F1分数: 0.7520, 训练样本数: 3646, 测试样本数: 912\n",
      "Estimators: DecisionTreeClassifier(max_depth=5, min_samples_split=91, random_state=42)\n",
      "AQUÍr\n",
      "\n",
      "客户端5训练中...\n",
      "客户端本地模型 - 准确率: 0.8487, F1分数: 0.7483, 训练样本数: 3648, 测试样本数: 912\n",
      "Estimators: DecisionTreeClassifier(max_depth=5, min_samples_split=91, random_state=42)\n",
      "AQUÍr\n",
      "第1步: 本地模型训练完成，规则已提取\n"
     ]
    }
   ],
   "source": [
    "# 4. 在每个客户端训练本地模型并提取规则\n",
    "print(\"\\n第1步: 训练本地模型并提取规则...\")\n",
    "client_models = []\n",
    "for i, data in enumerate(client_data):\n",
    "    print(f\"\\n客户端{i+1}训练中...\")\n",
    "    model = train_local_model(data, local_model_params)\n",
    "    client_models.append(model)\n",
    "print(\"第1步: 本地模型训练完成，规则已提取\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "第2-5步: 筛选弱决策树...\n",
      "客户端 1 正在评估所有树...\n",
      "客户端 2 正在评估所有树...\n",
      "客户端 3 正在评估所有树...\n",
      "客户端 4 正在评估所有树...\n",
      "客户端 5 正在评估所有树...\n",
      "筛选后选择了 2 棵树，索引: [1, 2]\n"
     ]
    }
   ],
   "source": [
    "# 3. 规则评估和筛选函数\n",
    "def evaluate_trees_on_client(client_model, all_models):\n",
    "    \"\"\"评估所有模型在当前客户端数据上的表现\"\"\"\n",
    "    X_test, y_test = client_model['X_test'], client_model['y_test']\n",
    "    eval_results = []\n",
    "    \n",
    "    for model in all_models:\n",
    "        tree = model['local_tree']\n",
    "        y_pred = tree.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average='macro')\n",
    "        eval_results.append((acc, f1))\n",
    "    \n",
    "    return eval_results\n",
    "\n",
    "def filter_trees(evaluation_results, filter_params):\n",
    "    \"\"\"基于评估结果筛选树\"\"\"\n",
    "    # 计算平均性能\n",
    "    avg_results = np.mean(evaluation_results, axis=0)\n",
    "    \n",
    "    # 根据筛选方法确定阈值\n",
    "    filter_method = filter_params.get('filter_method', 'mean')\n",
    "    if filter_method == 'mean':\n",
    "        acc_threshold = np.mean(avg_results[:,0])\n",
    "        f1_threshold = np.mean(avg_results[:,1])\n",
    "    elif filter_method == 'percentile':\n",
    "        percentile_value = filter_params.get('filter_value', 75)\n",
    "        acc_threshold = np.percentile(avg_results[:,0], percentile_value)\n",
    "        f1_threshold = np.percentile(avg_results[:,1], percentile_value)\n",
    "    else:\n",
    "        # 默认使用固定阈值\n",
    "        acc_threshold = filter_params.get('acc_threshold', 0.6)\n",
    "        f1_threshold = filter_params.get('f1_threshold', 0.5)\n",
    "    \n",
    "    # 筛选满足条件的树索引\n",
    "    selected_indices = []\n",
    "    for i in range(len(avg_results)):\n",
    "        # print(avg_results[i], acc_threshold, f1_threshold)\n",
    "        if avg_results[i][0] >= acc_threshold and avg_results[i][1] >= f1_threshold:\n",
    "            selected_indices.append(i)\n",
    "    \n",
    "    # 如果没有树被选中，选择表现最好的一棵\n",
    "    if not selected_indices:\n",
    "        best_idx = np.argmax(avg_results[0])  # 使用准确率选择\n",
    "        selected_indices = [best_idx]\n",
    "    \n",
    "    print(f\"筛选后选择了 {len(selected_indices)} 棵树，索引: {selected_indices}\")\n",
    "    return selected_indices\n",
    "\n",
    "\n",
    "# 5. 评估所有客户端上的所有树\n",
    "print(\"\\n第2-5步: 筛选弱决策树...\")\n",
    "all_evaluations = []\n",
    "for i, client_model in enumerate(client_models):\n",
    "    print(f\"客户端 {i+1} 正在评估所有树...\")\n",
    "    eval_results = evaluate_trees_on_client(client_model, client_models)\n",
    "    all_evaluations.append(eval_results)\n",
    "    \n",
    "# 6. 筛选表现好的树\n",
    "filter_params = {\n",
    "    'filter_method': FILTERING_METHOD,\n",
    "    'acc_threshold': ACC_THRESHOLD / 2, \n",
    "    'f1_threshold': F1_THRESHOLD / 2\n",
    "}\n",
    "    \n",
    "selected_indices = filter_trees(all_evaluations, filter_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "第6-9步: 聚合规则并构建全局模型...\n",
      "Estimators: None\n",
      "Iteration 1: 16 conjunctions\n",
      "\n",
      "Las reglas actuales son: \n",
      "Conjunction set length: 56\n",
      "Conjunction set length after removing duplicates: 56\n",
      "branches df aggreagator is not null:     0_upper  0_lower  1_upper  1_lower  2_upper  2_lower  3_upper  3_lower  \\\n",
      "0       inf     -inf   7139.5     -inf   2218.5     -inf     42.5     -inf   \n",
      "1       inf     -inf   7139.5     -inf   2248.0   2218.5     42.5     -inf   \n",
      "2       inf     -inf   7139.5     -inf   2248.0     -inf     42.5     -inf   \n",
      "3       inf     -inf   7139.5     -inf   2218.5     -inf     42.5     -inf   \n",
      "4       inf     -inf   7139.5     -inf   2248.0   2218.5     42.5     -inf   \n",
      "5       inf     -inf   7139.5     -inf   2248.0     -inf     42.5     -inf   \n",
      "6       inf     -inf   7139.5     -inf   2218.5     -inf     43.5     42.5   \n",
      "7       inf     -inf   7139.5     -inf   2218.5     -inf      inf     43.5   \n",
      "8       inf     -inf   7139.5     -inf   2248.0   2218.5      inf     42.5   \n",
      "9       inf     -inf   7139.5     -inf   2248.0     -inf      inf     42.5   \n",
      "10      inf     -inf   7139.5     -inf      inf   2248.0      inf     -inf   \n",
      "11      inf     -inf   7139.5     -inf      inf   2248.0      inf     -inf   \n",
      "12      inf     -inf      inf   7139.5      inf     -inf      inf     -inf   \n",
      "13     35.5     -inf   5095.5     -inf   1794.0     -inf      inf     -inf   \n",
      "14      inf     35.5   5095.5     -inf   1794.0     -inf      inf     -inf   \n",
      "15     35.5     -inf   5095.5     -inf   1794.0     -inf      inf     -inf   \n",
      "16      inf     35.5   5095.5     -inf   1794.0     -inf      inf     -inf   \n",
      "17     35.5     -inf   5095.5     -inf   1846.0   1794.0      inf     -inf   \n",
      "18      inf     35.5   5095.5     -inf   1846.0   1794.0      inf     -inf   \n",
      "19      inf     -inf   5095.5     -inf      inf   1846.0      inf     -inf   \n",
      "20      inf     -inf      inf   5095.5      inf     -inf      inf     -inf   \n",
      "21     35.5     -inf   2966.0     -inf   1794.0     -inf      inf     -inf   \n",
      "22     61.5     35.5   2966.0     -inf   1794.0     -inf      inf     -inf   \n",
      "23     61.5     -inf   2966.0     -inf   1794.0     -inf     27.5     -inf   \n",
      "24     61.5     -inf   2966.0     -inf   1794.0     -inf      inf     27.5   \n",
      "25      inf     61.5   2966.0     -inf   1794.0     -inf      inf     -inf   \n",
      "26      inf     61.5   2966.0     -inf   1794.0     -inf     27.5     -inf   \n",
      "27      inf     61.5   2966.0     -inf   1794.0     -inf      inf     27.5   \n",
      "28     35.5     -inf   2966.0     -inf   1846.0   1794.0      inf     -inf   \n",
      "29      inf     35.5   2966.0     -inf   1846.0   1794.0      inf     -inf   \n",
      "30      inf     -inf   2966.0     -inf      inf   1846.0      inf     -inf   \n",
      "31      inf     -inf   2966.0     -inf      inf   1794.0     27.5     -inf   \n",
      "32      inf     -inf   2966.0     -inf      inf   1794.0      inf     27.5   \n",
      "33     35.5     -inf   5095.5   2966.0   1846.0     -inf      inf     -inf   \n",
      "34     83.5     35.5   5095.5   2966.0   1846.0     -inf      inf     -inf   \n",
      "35     83.5     -inf   5095.5   2966.0      inf   1846.0      inf     -inf   \n",
      "36     83.5     -inf      inf   5095.5      inf     -inf      inf     -inf   \n",
      "37     83.5     -inf      inf   2966.0      inf     -inf     27.5     -inf   \n",
      "38     83.5     -inf   3120.0   2966.0      inf     -inf      inf     27.5   \n",
      "39     83.5     -inf   5095.5   3120.0      inf     -inf      inf     27.5   \n",
      "40     83.5     -inf      inf   5095.5      inf     -inf      inf     27.5   \n",
      "41     35.5     -inf   5095.5   2966.0   1846.0     -inf      inf     -inf   \n",
      "42     83.5     35.5   5095.5   2966.0   1846.0     -inf      inf     -inf   \n",
      "43     83.5     -inf   5095.5   2966.0      inf   1846.0      inf     -inf   \n",
      "44     83.5     -inf      inf   5095.5      inf     -inf      inf     -inf   \n",
      "45     83.5     -inf      inf   2966.0      inf     -inf     27.5     -inf   \n",
      "46     83.5     -inf   3120.0   2966.0      inf     -inf      inf     27.5   \n",
      "47     83.5     -inf   5095.5   3120.0      inf     -inf      inf     27.5   \n",
      "48     83.5     -inf      inf   5095.5      inf     -inf      inf     27.5   \n",
      "49      inf     83.5   5095.5   2966.0   1846.0     -inf      inf     -inf   \n",
      "50      inf     83.5   5095.5   2966.0      inf   1846.0      inf     -inf   \n",
      "51      inf     83.5      inf   5095.5      inf     -inf      inf     -inf   \n",
      "52      inf     83.5      inf   2966.0      inf     -inf     27.5     -inf   \n",
      "53      inf     83.5   3120.0   2966.0      inf     -inf      inf     27.5   \n",
      "54      inf     83.5   5095.5   3120.0      inf     -inf      inf     27.5   \n",
      "55      inf     83.5      inf   5095.5      inf     -inf      inf     27.5   \n",
      "\n",
      "    4_upper  4_lower  ...  104_lower  105_upper  105_lower  106_upper  \\\n",
      "0       inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "1       inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "2       inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "3       inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "4       inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "5       inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "6       inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "7       inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "8       inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "9       inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "10      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "11      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "12      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "13      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "14      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "15      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "16      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "17      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "18      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "19      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "20      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "21      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "22      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "23      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "24      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "25      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "26      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "27      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "28      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "29      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "30      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "31      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "32      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "33      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "34      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "35      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "36      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "37      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "38      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "39      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "40      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "41      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "42      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "43      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "44      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "45      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "46      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "47      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "48      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "49      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "50      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "51      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "52      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "53      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "54      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "55      inf     -inf  ...       -inf        inf       -inf        inf   \n",
      "\n",
      "    106_lower  107_upper  107_lower  number_of_samples  branch_probability  \\\n",
      "0        -inf        inf       -inf               1542            0.061607   \n",
      "1        -inf        inf       -inf                112            0.060505   \n",
      "2        -inf        inf       -inf                193            0.060505   \n",
      "3        -inf        inf       -inf                 55            0.061607   \n",
      "4        -inf        inf       -inf                  4            0.002741   \n",
      "5        -inf        inf       -inf                  7            0.002741   \n",
      "6        -inf        inf       -inf                766            0.061607   \n",
      "7        -inf        inf       -inf                378            0.026134   \n",
      "8        -inf        inf       -inf                 55            0.026134   \n",
      "9        -inf        inf       -inf                 17            0.002611   \n",
      "10       -inf        inf       -inf                 12            0.000697   \n",
      "11       -inf        inf       -inf                 21            0.002611   \n",
      "12       -inf        inf       -inf                 35            0.004064   \n",
      "13       -inf        inf       -inf                258            0.026014   \n",
      "14       -inf        inf       -inf                352            0.029225   \n",
      "15       -inf        inf       -inf                560            0.041649   \n",
      "16       -inf        inf       -inf                765            0.041649   \n",
      "17       -inf        inf       -inf                113            0.026014   \n",
      "18       -inf        inf       -inf                155            0.029225   \n",
      "19       -inf        inf       -inf                 36            0.001729   \n",
      "20       -inf        inf       -inf                 58            0.002933   \n",
      "21       -inf        inf       -inf                369            0.026014   \n",
      "22       -inf        inf       -inf                504            0.029225   \n",
      "23       -inf        inf       -inf                119            0.018022   \n",
      "24       -inf        inf       -inf                370            0.018022   \n",
      "25       -inf        inf       -inf                164            0.029225   \n",
      "26       -inf        inf       -inf                 38            0.002492   \n",
      "27       -inf        inf       -inf                120            0.015914   \n",
      "28       -inf        inf       -inf                136            0.026014   \n",
      "29       -inf        inf       -inf                186            0.029225   \n",
      "30       -inf        inf       -inf                 43            0.001558   \n",
      "31       -inf        inf       -inf                 44            0.002492   \n",
      "32       -inf        inf       -inf                136            0.015914   \n",
      "33       -inf        inf       -inf                184            0.026014   \n",
      "34       -inf        inf       -inf                252            0.029225   \n",
      "35       -inf        inf       -inf                 58            0.001558   \n",
      "36       -inf        inf       -inf                 76            0.002933   \n",
      "37       -inf        inf       -inf                 59            0.002492   \n",
      "38       -inf        inf       -inf                185            0.015914   \n",
      "39       -inf        inf       -inf                 33            0.001484   \n",
      "40       -inf        inf       -inf                 78            0.001484   \n",
      "41       -inf        inf       -inf                 27            0.026014   \n",
      "42       -inf        inf       -inf                 38            0.029225   \n",
      "43       -inf        inf       -inf                  9            0.001558   \n",
      "44       -inf        inf       -inf                 11            0.002933   \n",
      "45       -inf        inf       -inf                  9            0.002492   \n",
      "46       -inf        inf       -inf                 28            0.015914   \n",
      "47       -inf        inf       -inf                  5            0.000415   \n",
      "48       -inf        inf       -inf                 12            0.000844   \n",
      "49       -inf        inf       -inf                 27            0.029225   \n",
      "50       -inf        inf       -inf                  6            0.001558   \n",
      "51       -inf        inf       -inf                  8            0.002933   \n",
      "52       -inf        inf       -inf                  6            0.002492   \n",
      "53       -inf        inf       -inf                 19            0.015914   \n",
      "54       -inf        inf       -inf                  3            0.000415   \n",
      "55       -inf        inf       -inf                  8            0.000844   \n",
      "\n",
      "                                        probas  \n",
      "0    [0.979586609172293, 0.020413390827706993]  \n",
      "1     [0.6140885750962772, 0.3859114249037227]  \n",
      "2     [0.6765885750962772, 0.3234114249037227]  \n",
      "3     [0.4904980340760157, 0.5095019659239842]  \n",
      "4                               [0.125, 0.875]  \n",
      "5                             [0.1875, 0.8125]  \n",
      "6    [0.9255629691409508, 0.07443703085904921]  \n",
      "7     [0.8744180347953933, 0.1255819652046067]  \n",
      "8     [0.560064935064935, 0.43993506493506496]  \n",
      "9     [0.2708333333333333, 0.7291666666666667]  \n",
      "10   [0.28289473684210525, 0.7171052631578947]  \n",
      "11   [0.34539473684210525, 0.6546052631578947]  \n",
      "12   [0.04206349206349206, 0.9579365079365079]  \n",
      "13    [0.877057210031348, 0.12294278996865204]  \n",
      "14   [0.7857390393294649, 0.21426096067053516]  \n",
      "15   [0.7733930868500767, 0.22660691314992323]  \n",
      "16   [0.6820749161481936, 0.31792508385180634]  \n",
      "17    [0.5633874239350912, 0.4366125760649088]  \n",
      "18   [0.47206925323320814, 0.5279307467667919]  \n",
      "19   [0.25077399380804954, 0.7492260061919505]  \n",
      "20  [0.009433962264150943, 0.9905660377358491]  \n",
      "21   [0.6152450090744102, 0.38475499092558985]  \n",
      "22   [0.5239268383725271, 0.47607316162747293]  \n",
      "23    [0.5560053981106613, 0.4439946018893387]  \n",
      "24   [0.32141369254270236, 0.6785863074572975]  \n",
      "25    [0.6949794699514744, 0.3050205300485256]  \n",
      "26   [0.7270580296896086, 0.27294197031039136]  \n",
      "27   [0.49246632412164976, 0.5075336758783502]  \n",
      "28     [0.4718508092892329, 0.528149190710767]  \n",
      "29    [0.3805326385873498, 0.6194673614126502]  \n",
      "30    [0.1592373791621912, 0.8407626208378088]  \n",
      "31   [0.41261119832548404, 0.5873888016745159]  \n",
      "32   [0.17801949275752516, 0.8219805072424748]  \n",
      "33    [0.4365900383141762, 0.5634099616858238]  \n",
      "34    [0.3452718676122931, 0.6547281323877069]  \n",
      "35   [0.12397660818713449, 0.8760233918128655]  \n",
      "36  [0.005555555555555556, 0.9944444444444445]  \n",
      "37   [0.37735042735042734, 0.6226495726495727]  \n",
      "38   [0.14275872178246848, 0.8572412782175316]  \n",
      "39    [0.4222222222222222, 0.5777777777777778]  \n",
      "40  [0.005555555555555556, 0.9944444444444445]  \n",
      "41   [0.6810344827586207, 0.31896551724137934]  \n",
      "42    [0.5897163120567376, 0.4102836879432624]  \n",
      "43     [0.3684210526315789, 0.631578947368421]  \n",
      "44                                [0.25, 0.75]  \n",
      "45    [0.6217948717948718, 0.3782051282051282]  \n",
      "46    [0.3872031662269129, 0.6127968337730871]  \n",
      "47    [0.6666666666666667, 0.3333333333333333]  \n",
      "48                                [0.25, 0.75]  \n",
      "49   [0.8397163120567376, 0.16028368794326242]  \n",
      "50     [0.618421052631579, 0.3815789473684211]  \n",
      "51                                  [0.5, 0.5]  \n",
      "52    [0.8717948717948718, 0.1282051282051282]  \n",
      "53    [0.6372031662269129, 0.3627968337730871]  \n",
      "54   [0.9166666666666667, 0.08333333333333333]  \n",
      "55                                  [0.5, 0.5]  \n",
      "\n",
      "[56 rows x 219 columns]\n",
      "全局模型构建完成\n"
     ]
    }
   ],
   "source": [
    "# 4. 规则聚合函数\n",
    "def aggregate_rules(client_models, selected_indices):\n",
    "    \"\"\"聚合所选客户端的规则\"\"\"\n",
    "    # 仅保留所选树的规则\n",
    "    selected_models = [client_models[i] for i in selected_indices]\n",
    "    \n",
    "    # 提取规则和类别\n",
    "    client_branches = [model['local_branches'] for model in selected_models]\n",
    "    client_classes = [model['local_classes'] for model in selected_models]\n",
    "    client_branches_df = [model['local_branches_df'] for model in selected_models]\n",
    "    model_types = ['cart'] * len(selected_models)  # 简化为只使用CART\n",
    "    \n",
    "    \n",
    "    # 准备输入格式\n",
    "    list_of_weights = [(branches, classes, branches_df, model_type) \n",
    "                       for branches, classes, branches_df, model_type in \n",
    "                       zip(client_branches, client_classes, client_branches_df, model_types)]\n",
    "    \n",
    "    # 提取所有类别和特征\n",
    "    classes_ = set()\n",
    "    for client_class in client_classes:\n",
    "        classes_ |= set(client_class)\n",
    "    classes_ = list(classes_)\n",
    "    \n",
    "    # 提取分支列表\n",
    "    client_cs = [cs for cs in client_branches]\n",
    "    \n",
    "    # 聚合为全局模型\n",
    "    global_model = generate_cs_dt_branches_from_list(client_cs, classes_, TreeBranch)\n",
    "    \n",
    "    return global_model\n",
    "\n",
    "# 7. 聚合规则并构建全局模型\n",
    "print(\"\\n第6-9步: 聚合规则并构建全局模型...\")\n",
    "global_model = aggregate_rules(client_models, selected_indices)\n",
    "print(\"全局模型构建完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 全局模型评估函数\n",
    "def evaluate_global_model(global_model, test_data):\n",
    "    \"\"\"评估全局聚合模型的性能\"\"\"\n",
    "    X_test, y_test = test_data.to_numpy()\n",
    "    \n",
    "    # 从全局模型中获取分支类别\n",
    "    branches_df = global_model[2]\n",
    "    classes_tree = get_classes_branches(branches_df)\n",
    "    \n",
    "    # 使用全局模型进行预测\n",
    "    y_pred, _ = global_model[1].predict(X_test, classes_tree, branches_df)\n",
    "    \n",
    "    # 计算性能指标\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(\"\\n全局模型在测试集上的性能:\")\n",
    "    print(f\"准确率: {acc:.4f}\")\n",
    "    print(f\"宏平均F1: {f1:.4f}\")\n",
    "    print(f\"分类报告: \\n{report}\")\n",
    "    \n",
    "    return acc, f1\n",
    "\n",
    "def get_classes_branches(branches):\n",
    "    \"\"\"从分支DataFrame中获取类别\"\"\"\n",
    "    assert branches is not None\n",
    "    return list(range(len(branches['probas'].iloc[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "第10步: 评估全局模型...\n",
      "\n",
      "全局模型在测试集上的性能:\n",
      "准确率: 0.8509\n",
      "宏平均F1: 0.7757\n",
      "分类报告: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.91      7412\n",
      "           1       0.76      0.56      0.65      2357\n",
      "\n",
      "    accuracy                           0.85      9769\n",
      "   macro avg       0.81      0.75      0.78      9769\n",
      "weighted avg       0.84      0.85      0.84      9769\n",
      "\n",
      "\n",
      "--- ICDTA4FL 简化Demo完成 ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 8. 评估全局模型\n",
    "print(\"\\n第10步: 评估全局模型...\")\n",
    "eval_results = evaluate_global_model(global_model, test_data)\n",
    "    \n",
    "print(\"\\n--- ICDTA4FL 简化Demo完成 ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtfl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
